{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping using Beautiful Soup in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data required is from a Wiki page containing a table. We will use Beautiful Soup to extract the table and insert it into a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL given \n",
    "url = 'https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M'\n",
    "source = requests.get(url).text\n",
    "soup = BeautifulSoup(source, 'lxml')\n",
    "\n",
    "body = soup.find('body')\n",
    "table = body.find('table', class_ = \"wikitable sortable\")\n",
    "table_rows = table.find_all('tr')\n",
    "\n",
    "data = [] #Stores the Data\n",
    "column_name = ['Postcode', 'Boroughs', 'Neighborhoods'] #Name of the Columns for the Dataframe\n",
    "\n",
    "for tr in table_rows:\n",
    "    td = tr.find_all('td')\n",
    "    row_data = [tr.text for tr in td]\n",
    "    data.append(row_data)\n",
    "    \n",
    "df = pd.DataFrame(data, columns = column_name)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now clean up the data according to the following rules:\n",
    "\n",
    "* The dataframe will consist of three columns: PostalCode, Borough, and Neighborhood\n",
    "\n",
    "* Only process the cells that have an assigned borough. Ignore cells with a borough that is Not assigned.\n",
    "\n",
    "* More than one neighborhood can exist in one postal code area. For example, in the table on the Wikipedia page, you will notice that M5A is listed twice and has two neighborhoods: Harbourfront and Regent Park. These two rows will be combined into one row with the neighborhoods separated with a comma as shown in row 11 in the above table.\n",
    "\n",
    "* If a cell has a borough but a Not assigned neighborhood, then the neighborhood will be the same as the borough. So for the 9th cell in the table on the Wikipedia page, the value of the Borough and the Neighborhood columns will be Queen's Park."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the first row\n",
    "df.drop(0, axis = 0, inplace = True) \n",
    "\n",
    "#Drop rows were borough is not assigned\n",
    "df.drop(df[df['Boroughs'] == 'Not assigned'].index, axis = 0, inplace = True) \n",
    "\n",
    "#Replace the additional '\\n' in the Neighborhoods column with ''\n",
    "df['Neighborhoods'] = df['Neighborhoods'].str.replace('\\n','')\n",
    "\n",
    "#Group neighborhoods with the same postal code\n",
    "df = df.groupby(['Postcode','Boroughs'])['Neighborhoods'].apply(lambda x: \"%s\" % ', '.join(x)).to_frame().reset_index()\n",
    "\n",
    "#For 'Not assigned' neighborhoods, the neighborhood will be the same as the borough\n",
    "df.loc[(df.Neighborhoods == 'Not assigned'), 'Neighborhoods'] = df['Boroughs']\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
